{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Flooding Areas from NRT Sentinel-1 Satellite Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, GeoData, LayersControl\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These files were obtained using the ASF Vertex Data Search.\n",
    "They were submitted for Radio Terrain Correctiom.\n",
    "radiometry: gamma0\n",
    "scale: decibel\n",
    "pixel spacing: 10m\n",
    "\"\"\"\n",
    "\n",
    "box_data = {\n",
    "    'zipfile': ['S1A_IW_20250205T233956_DVP_RTC10_G_gdufem_246A.zip',\n",
    "                'S1A_IW_20250217T233955_DVP_RTC10_G_gdufem_E701.zip'],\n",
    "    'link': ['https://ky.box.com/shared/static/xwhzpb6entefdhsi8jfhgii1f4ehh6x6.zip', \n",
    "             'https://ky.box.com/shared/static/81wf3fabzhzsux29nhe4ojdaq0qtwp89.zip']\n",
    "        }\n",
    "df = pd.DataFrame(data=box_data)\n",
    "\n",
    "base_scene = df.at[0,'zipfile']\n",
    "base_dir = os.path.splitext(base_scene)[0]\n",
    "flood_scene = df.at[1, 'zipfile']\n",
    "flood_dir = os.path.splitext(flood_scene)[0]\n",
    "\n",
    "print(f'Base Image: {base_dir}\\nFlood Image: {flood_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download files from Box\\* \\*\\*\n",
    "\n",
    "\\* At first I create a function to use the Box download link, but it was corrupting the file and not letting me unzip.  As a last resort, I'm using subprocess.\n",
    "\n",
    "\\*\\* If all else fails, the download links can be used to directly download files and unzip locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_download(df):\n",
    "    out_folder = \"data\"\n",
    "    download_zip = os.path.join(out_folder, 'file.zip')\n",
    "    for row_index, row in df.iterrows():\n",
    "        link = row['link']\n",
    "        unzipped_folder = os.path.splitext(row['zipfile'])[0]  # get basename of zip file\n",
    "        unzip_path = os.path.join(out_folder, unzipped_folder)\n",
    "\n",
    "        cmd = f\"curl -L -o {download_zip} {link} && unzip {download_zip} -d {out_folder}\"\n",
    "        \n",
    "        if not os.path.exists(unzip_path):\n",
    "            subprocess.run(cmd, shell=True, check=True)\n",
    "            # delete downloaded zip file.\n",
    "            os.remove(download_zip)\n",
    "        else:\n",
    "            print(f'Extracted Files already exist for \"{unzipped_folder}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think using multiprocessing helps now that I'm using a subprocess, but it's not hurting it either.\n",
    "\n",
    "Download could take several minutes, depending upon bandwidth.  Zipped up, the scenes are over 10gb in size each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_cores = multiprocessing.cpu_count()\n",
    "# determine number of threads to use for multiprocessing\n",
    "num_workers = int(logical_cores * 0.75)  # rounds down in case not a whole number\n",
    "print(f'Number of threads to use: {num_workers}')\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    executor.map(box_download(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the README.md.txt file\n",
    "\n",
    "The folders contain several files.  Each image (png or tif) has a corresponding metadata (xml) file.  The folder also includes a shapefile (\\*_shape.\\*) and a google kmz which display a geometry on a map.  There is also a README.md.txt file in each folder that breaks down how to undertand the file name and what is included in the scene folder.  Try \n",
    "removing the *.txt* and open with a Markdown Viewer.  \n",
    "\n",
    "Let's take a look at some of the files to get an idea of what we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/S1A_IW_20250205T233956_DVP_RTC10_G_gdufem_246A/S1A_IW_20250205T233956_DVP_RTC10_G_gdufem_246A_shape.shp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ad172ce42440bc810eb19559612f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GeoData(data={'type': 'FeatureCollection', 'features': [{'id': '0', 'type': 'Feature', 'properties': {'value':â€¦"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory as variable for simplicity\n",
    "# read in base image kmz.\n",
    "base_shapefile = (f'data/{base_dir}/{base_dir}_shape.shp')\n",
    "print(base_shapefile)\n",
    "\n",
    "# read in shapefile to geodataframe\n",
    "gdf_base_shapefile = gpd.read_file(base_shapefile)\n",
    "# print(gdf_base_shapefile.plot())\n",
    "\n",
    "# read in geodataframe to a ipyleaflet GeoData\n",
    "base_geo_data = GeoData(geo_dataframe = gdf_base_shapefile,\n",
    "                   style={'color': 'black', 'fillColor': '#3366cc', 'opacity':0.05, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.6},\n",
    "                   hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                   name = 'base Geometry')\n",
    "base_geo_data.set_crs(\"EPSG:4326\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.CartoDB.Positron),\n",
    "    center=(38, -85),\n",
    "    zoom=5\n",
    ")\n",
    "m.add(base_geo_data)\n",
    "# m.add(LayersContol())\n",
    "m\n",
    "# sc = Sidecar(title='Map')\n",
    "# with sc:\n",
    "#     display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
