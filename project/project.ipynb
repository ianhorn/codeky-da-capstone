{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Flooding Areas from NRT Sentinel-1 Satellite Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd            # ready geospatial data\n",
    "import os\n",
    "import subprocess              # for multithreading\n",
    "import multiprocessing         #  \"     \"      \"\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles \n",
    "from ipyleaflet import GeoData, LayersControl, ImageOverlay\n",
    "import geopandas as gpd\n",
    "from sidecar import Sidecar\n",
    "import ipywidgets as widgets     # interactive display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Image: S1A_IW_20250205T233956_DVP_RTC10_G_gdufem_246A\n",
      "Flood Image: S1A_IW_20250217T233955_DVP_RTC10_G_gdufem_E701\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "These files were obtained using the ASF Vertex Data Search.\n",
    "They were submitted for Radio Terrain Correctiom.\n",
    "radiometry: gamma0\n",
    "scale: decibel\n",
    "pixel spacing: 10m\n",
    "\"\"\"\n",
    "\n",
    "box_data = {\n",
    "    'zipfile': ['S1A_IW_20250205T233956_DVP_RTC10_G_gdufem_246A.zip',\n",
    "                'S1A_IW_20250217T233955_DVP_RTC10_G_gdufem_E701.zip'],\n",
    "    'link': ['https://ky.box.com/shared/static/xwhzpb6entefdhsi8jfhgii1f4ehh6x6.zip', \n",
    "             'https://ky.box.com/shared/static/81wf3fabzhzsux29nhe4ojdaq0qtwp89.zip']\n",
    "        }\n",
    "df = pd.DataFrame(data=box_data)\n",
    "\n",
    "base_scene = df.at[0,'zipfile']\n",
    "base_dir = os.path.splitext(base_scene)[0]\n",
    "flood_scene = df.at[1, 'zipfile']\n",
    "flood_dir = os.path.splitext(flood_scene)[0]\n",
    "\n",
    "print(f'Base Image: {base_dir}\\nFlood Image: {flood_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download files from Box\\* \\*\\*\n",
    "\n",
    "\\* At first I create a function to use the Box download link, but it was corrupting the file and not letting me unzip.  As a last resort, I'm using subprocess.\n",
    "\n",
    "\\*\\* If all else fails, the download links can be used to directly download files and unzip locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_download(df):\n",
    "    out_folder = \"data\"\n",
    "    download_zip = os.path.join(out_folder, 'file.zip')\n",
    "    for row_index, row in df.iterrows():\n",
    "        link = row['link']\n",
    "        unzipped_folder = os.path.splitext(row['zipfile'])[0]  # get basename of zip file\n",
    "        unzip_path = os.path.join(out_folder, unzipped_folder)\n",
    "\n",
    "        cmd = f\"curl -L -o {download_zip} {link} && unzip {download_zip} -d {out_folder}\"\n",
    "        \n",
    "        if not os.path.exists(unzip_path):\n",
    "            subprocess.run(cmd, shell=True, check=True)\n",
    "            # delete downloaded zip file.\n",
    "            os.remove(download_zip)\n",
    "        else:\n",
    "            print(f'Extracted Files already exist for \"{unzipped_folder}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think using multiprocessing helps now that I'm using a subprocess, but it's not hurting it either.\n",
    "\n",
    "Download could take several minutes, depending upon bandwidth.  Zipped up, the scenes are over 10gb in size each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads to use: 7\n",
      "Extracted Files already exist for \"S1A_IW_20250205T233956_DVP_RTC10_G_gdufem_246A\"\n",
      "Extracted Files already exist for \"S1A_IW_20250217T233955_DVP_RTC10_G_gdufem_E701\"\n"
     ]
    }
   ],
   "source": [
    "logical_cores = multiprocessing.cpu_count()\n",
    "# determine number of threads to use for multiprocessing\n",
    "num_workers = int(logical_cores * 0.75)  # rounds down in case not a whole number\n",
    "print(f'Number of threads to use: {num_workers}')\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    executor.map(box_download(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the README.md.txt file\n",
    "\n",
    "The folders contain several files.  Each image (png or tif) has a corresponding metadata (xml) file.  The folder also includes a shapefile (\\*_shape.\\*) and a google kmz which display a geometry on a map.  There is also a README.md.txt file in each folder that breaks down how to undertand the file name and what is included in the scene folder.  Try \n",
    "removing the *.txt* and open with a Markdown Viewer.  \n",
    "\n",
    "Let's take a look at some of the files to get an idea of what we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source projection: EPSG:32616\n",
      "redefined projection: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# read in base image shapefile\n",
    "base_shapefile = (f'data/{base_dir}/{base_dir}_shape.shp')\n",
    "\n",
    "# read in shapefile to geodataframe\n",
    "gdf_base_shapefile = gpd.read_file(base_shapefile)\n",
    "print(f'source projection: {gdf_base_shapefile.crs}')\n",
    "\n",
    "# redefine the projection to work with the map\n",
    "gdf_base_shapefile = gdf_base_shapefile.to_crs('EPSG:4326')\n",
    "print(f'redefined projection: {gdf_base_shapefile.crs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in geodataframe to a ipyleaflet GeoData\n",
    "base_geo_data = GeoData(geo_dataframe = gdf_base_shapefile,\n",
    "                   style={'color': 'black', 'fillColor': '#3366cc', 'opacity':0.1, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.6},\n",
    "                   hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                   name = 'base Geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f1a802c12040ab89dc46a72cc18fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38, -85.5], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.CartoDB.Positron),\n",
    "    center=(38, -85.5),\n",
    "    zoom=7.3\n",
    ")\n",
    "m.add(base_geo_data)\n",
    "# m.add(LayersContol())\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Add a section that creates a grid to display several images side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note how we can see the Ohio River starting near the uppermost right corner,\n",
      "extending to middle on the left.  This is the derived RGB image.  It will\n",
      "not be used for analysis.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3ea77e22a649a0b668dbdce7bda274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x08\\x00\\x00\\x00\\x05\\xfd\\x08\\x02\\x00\\x00\\x00\\xf5\\x1e/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display RGB Composite File\n",
    "rgb_png = './data/S1A_IW_20250217T233955_DVP_RTC10_G_gdufem_E701/S1A_IW_20250217T233955_DVP_RTC10_G_gdufem_E701_rgb.png'\n",
    "file = open(rgb_png, \"rb\")\n",
    "image = file.read()\n",
    "image_widget = widgets.Image(\n",
    "    value=image,\n",
    "    format='png',\n",
    "    width=300,\n",
    "    height=400,\n",
    ")\n",
    "print(\"\\nNote how we can see the Ohio River starting near the uppermost right corner,\\nextending to middle on the left.  This is the derived RGB image.  It will\\nnot be used for analysis.\")\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
